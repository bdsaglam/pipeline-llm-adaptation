{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_tuple(x):\n",
    "    return tuple(sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'commit': 'workspace',\n",
       " 'id': 'workspace',\n",
       " 'name': None,\n",
       " 'params': {'task': 'erx',\n",
       "  'train': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'train[:100]'},\n",
       "   'optimizer': 'noop',\n",
       "   'ensemble': 'no'},\n",
       "  'evaluation': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'dev'}},\n",
       "  'program': {'prompting': 'structured'},\n",
       "  'lm': {'model': 'llama-3-8b', 'temperature': 0.0},\n",
       "  'run': 1},\n",
       " 'metrics': {'exact.precision': 0.014585968840764236,\n",
       "  'exact.recall': 0.013411106866989222,\n",
       "  'exact.f1': 0.013893968089212146,\n",
       "  'fuzzy.precision': 0.2980273675422333,\n",
       "  'fuzzy.recall': 0.2736804602675239,\n",
       "  'fuzzy.f1': 0.28203483319061007}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapt.dvc import load_experiments\n",
    "\n",
    "filepaths = list(Path(\"../../tmp/erx/\").glob(\"*.json\"))\n",
    "experiments = [exp for fp in filepaths for exp in load_experiments(fp)]\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 experiments before preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>...</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff400268c8547f877d473be79df51695b9a1d9ed</td>\n",
       "      <td>round-duff</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:16]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tiny</td>\n",
       "      <td>0.076155</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.253334</td>\n",
       "      <td>0.248191</td>\n",
       "      <td>0.237905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        name params.task  \\\n",
       "0                                 workspace        None         erx   \n",
       "1  ff400268c8547f877d473be79df51695b9a1d9ed  round-duff         erx   \n",
       "\n",
       "     params.train.dataset.path params.train.dataset.name  \\\n",
       "0  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "  params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                train[:100]                   noop                    no   \n",
       "1                 train[:16]                   noop                    no   \n",
       "\n",
       "  params.evaluation.dataset.path params.evaluation.dataset.name  ...  \\\n",
       "0    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "1    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "\n",
       "  params.program.prompting params.lm.model params.lm.temperature  params.run  \\\n",
       "0               structured      llama-3-8b                   0.0           1   \n",
       "1                      sft  llama-3-8b-sft                   0.0        tiny   \n",
       "\n",
       "  metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "0                0.014586              0.013411          0.013894   \n",
       "1                0.076155              0.079555          0.074850   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "0                 0.298027              0.273680          0.282035  \n",
       "1                 0.253334              0.248191          0.237905  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(experiments).drop(columns=[\"commit\"])\n",
    "print(f\"{len(df)} experiments before preprocessing\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['name'].isin(['crumb-geum'])\n",
    "df = df.loc[~mask].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['params.program.prompting'] = df['params.program.prompting'].fillna('structured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 experiments after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>...</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff400268c8547f877d473be79df51695b9a1d9ed</td>\n",
       "      <td>round-duff</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:16]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tiny</td>\n",
       "      <td>0.076155</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.253334</td>\n",
       "      <td>0.248191</td>\n",
       "      <td>0.237905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        name params.task  \\\n",
       "0                                 workspace        None         erx   \n",
       "1  ff400268c8547f877d473be79df51695b9a1d9ed  round-duff         erx   \n",
       "\n",
       "     params.train.dataset.path params.train.dataset.name  \\\n",
       "0  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "  params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                train[:100]                   noop                    no   \n",
       "1                 train[:16]                   noop                    no   \n",
       "\n",
       "  params.evaluation.dataset.path params.evaluation.dataset.name  ...  \\\n",
       "0    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "1    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "\n",
       "  params.program.prompting params.lm.model params.lm.temperature  params.run  \\\n",
       "0               structured      llama-3-8b                   0.0           1   \n",
       "1                      sft  llama-3-8b-sft                   0.0        tiny   \n",
       "\n",
       "  metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "0                0.014586              0.013411          0.013894   \n",
       "1                0.076155              0.079555          0.074850   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "0                 0.298027              0.273680          0.282035  \n",
       "1                 0.253334              0.248191          0.237905  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=param_cols + metric_cols, inplace=True, how=\"any\")\n",
    "df.drop_duplicates(subset=param_cols, inplace=True, keep='last')\n",
    "\n",
    "print(f\"{len(df)} experiments after preprocessing\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- params.task: ['erx']\n",
      "\n",
      "- params.train.dataset.path: ['bdsaglam/web_nlg-erx-concat']\n",
      "\n",
      "- params.train.dataset.name: ['release_v3.0_en']\n",
      "\n",
      "- params.train.dataset.split: ['train[:100]', 'train[:16]']\n",
      "\n",
      "- params.train.optimizer: ['noop']\n",
      "\n",
      "- params.train.ensemble: ['no']\n",
      "\n",
      "- params.evaluation.dataset.path: ['bdsaglam/web_nlg-erx-concat']\n",
      "\n",
      "- params.evaluation.dataset.name: ['release_v3.0_en']\n",
      "\n",
      "- params.evaluation.dataset.split: ['dev']\n",
      "\n",
      "- params.program.prompting: ['structured', 'sft']\n",
      "\n",
      "- params.lm.model: ['llama-3-8b', 'llama-3-8b-sft']\n",
      "\n",
      "- params.lm.temperature: [np.float64(0.0)]\n",
      "\n",
      "- params.run: [1, 'tiny']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in param_cols:\n",
    "    values = list(df[col].unique())\n",
    "    print(f\"- {col}: {values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('exps-2.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "stop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/baris/repos/pipeline-llm-adaptation/nbs/erx/preprocess.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bbiltir-baris/home/baris/repos/pipeline-llm-adaptation/nbs/erx/preprocess.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mstop\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mException\u001b[0m: stop"
     ]
    }
   ],
   "source": [
    "raise Exception(\"stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup remaining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('exps.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_experiment_configs(common_params, varying_params):\n",
    "    # Generate all possible combinations of parameters\n",
    "    varying_params = {**common_params, **varying_params}\n",
    "    keys = varying_params.keys()\n",
    "    values = varying_params.values()\n",
    "    for instance in itertools.product(*values):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_all_experiment_configs(common_params: dict, varying_params_list: list[dict]):\n",
    "    for params in varying_params_list:\n",
    "        for exp_config in produce_experiment_configs(common_params, params):\n",
    "            yield exp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    \"params.task\": [\"erx\"],\n",
    "    \"params.train.dataset.path\": [\"bdsaglam/web_nlg-erx-concat\"],\n",
    "    \"params.train.dataset.name\": [\"release_v3.0_en\"],\n",
    "    \"params.train.dataset.split\": ['\"train[:100]\"'],\n",
    "    \"params.evaluation.dataset.path\": [\"bdsaglam/web_nlg-erx-concat\"],\n",
    "    \"params.evaluation.dataset.name\": [\"release_v3.0_en\"],\n",
    "    \"params.evaluation.dataset.split\": ['\"dev\"'],\n",
    "    \"params.train.ensemble\": [\n",
    "        \"no\",\n",
    "        # \"yes\",\n",
    "    ],\n",
    "    \"params.lm.temperature\": [\n",
    "        0.0,\n",
    "        # 0.5,\n",
    "        # 0.7,\n",
    "    ],\n",
    "    \"params.run\": [\n",
    "        1,\n",
    "        # 2,\n",
    "        # 3,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_params_list = [\n",
    "    {\n",
    "        \"params.train.optimizer\": [\n",
    "            \"noop\",\n",
    "            \"bfsrs-medium\",\n",
    "            \"bfsrs-high\",\n",
    "            'bfsrs-ulti',\n",
    "            \"miprov2-light\",\n",
    "            \"miprov2-medium\",\n",
    "        ],\n",
    "        \"params.program.prompting\": [\"structured\"],\n",
    "        \"params.lm.model\": [\n",
    "            # \"llama-3-8b\",\n",
    "            # \"qwen-2.5-32b\",\n",
    "            \"llama-3.3-70b\",\n",
    "        ],\n",
    "    },\n",
    "    # {\n",
    "    #     \"params.train.optimizer\": [\"noop\"],\n",
    "    #     \"params.program.prompting\": [\"sft\"],\n",
    "    #     \"params.lm.model\": [\n",
    "    #         \"llama-3-8b-sft\",\n",
    "    #     ],\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiment configurations\n",
      "['params.task', 'params.train.dataset.path', 'params.train.dataset.name', 'params.train.dataset.split', 'params.evaluation.dataset.path', 'params.evaluation.dataset.name', 'params.evaluation.dataset.split', 'params.train.ensemble', 'params.lm.temperature', 'params.run', 'params.train.optimizer', 'params.program.prompting', 'params.lm.model']\n"
     ]
    }
   ],
   "source": [
    "exp_configs = list(produce_all_experiment_configs(common_params, varying_params_list))\n",
    "target_params = list(exp_configs[0].keys())\n",
    "print(f\"{len(exp_configs)} experiment configurations\")\n",
    "print(target_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing exps: 26\n"
     ]
    }
   ],
   "source": [
    "if len(df):\n",
    "    existing_configs = df[target_params].to_dict(orient=\"records\")\n",
    "    existing_configs[0]\n",
    "else:\n",
    "    existing_configs = []\n",
    "\n",
    "print(\"Existing exps:\", len(existing_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 missing configurations\n"
     ]
    }
   ],
   "source": [
    "# find the missing configurations\n",
    "missing_configs = [\n",
    "    dict(kv)\n",
    "    for kv in list(\n",
    "        {tuple(sorted(config.items())) for config in exp_configs}\n",
    "        - {tuple(sorted(config.items())) for config in existing_configs}\n",
    "    )\n",
    "]\n",
    "print(f\"{len(missing_configs)} missing configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_command(exp_config):\n",
    "    lines = [\"dvc exp run --queue\"]\n",
    "    for target_param in target_params:\n",
    "        arg_name = target_param.split(\".\", 1)[-1]\n",
    "        arg_value = exp_config[target_param]\n",
    "        lines.append(f\"-S {arg_name}='{arg_value}'\")\n",
    "\n",
    "    command = \" \\\\\\n    \".join(lines)\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run.sh\", \"w\") as f:\n",
    "    f.write(\"#!/bin/sh\\n\\n\")\n",
    "    for exp_config in missing_configs:\n",
    "        f.write(make_command(exp_config))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.run</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>reference</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>moral-prof</td>\n",
       "      <td>sft</td>\n",
       "      <td>high</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spicy-teff</td>\n",
       "      <td>sft</td>\n",
       "      <td>medium</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>sft</td>\n",
       "      <td>low</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>alone-mesh</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>metal-pons</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377839</td>\n",
       "      <td>0.367084</td>\n",
       "      <td>0.370645</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>0.783746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gawsy-paps</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-ulti</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320626</td>\n",
       "      <td>0.319126</td>\n",
       "      <td>0.318514</td>\n",
       "      <td>0.698233</td>\n",
       "      <td>0.695948</td>\n",
       "      <td>0.693846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>slack-poss</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>veiny-mina</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>modal-huck</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.268814</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.666549</td>\n",
       "      <td>0.656943</td>\n",
       "      <td>0.657637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>unlet-hull</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>heigh-mope</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.251933</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.246764</td>\n",
       "      <td>0.650937</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.636171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mired-bats</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>kooky-choc</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.230381</td>\n",
       "      <td>0.214486</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>0.643391</td>\n",
       "      <td>0.597861</td>\n",
       "      <td>0.615783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>zippy-cane</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>soupy-beak</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.156003</td>\n",
       "      <td>0.155215</td>\n",
       "      <td>0.562983</td>\n",
       "      <td>0.569753</td>\n",
       "      <td>0.562845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>shoal-dolt</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>group-nuke</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>myoid-kefs</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.070684</td>\n",
       "      <td>0.532639</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>0.525673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sated-pond</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>butch-keek</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.447680</td>\n",
       "      <td>0.430505</td>\n",
       "      <td>0.436040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minim-rods</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sonic-doll</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>0.339312</td>\n",
       "      <td>0.340013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>None</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>None</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>round-duff</td>\n",
       "      <td>sft</td>\n",
       "      <td>tiny</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076155</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>0.074850</td>\n",
       "      <td>0.253334</td>\n",
       "      <td>0.248191</td>\n",
       "      <td>0.237905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name params.program.prompting params.run params.train.optimizer  \\\n",
       "24   reference               structured          1                   noop   \n",
       "1   moral-prof                      sft       high                   noop   \n",
       "2   spicy-teff                      sft     medium                   noop   \n",
       "0   lathy-jaws                      sft        low                   noop   \n",
       "19  alone-mesh               structured          1           bfsrs-medium   \n",
       "4   metal-pons               structured          1           bfsrs-medium   \n",
       "3   gawsy-paps               structured          1             bfsrs-ulti   \n",
       "20  slack-poss               structured          1           bfsrs-medium   \n",
       "15  veiny-mina               structured          1             bfsrs-high   \n",
       "9   modal-huck               structured          1             bfsrs-high   \n",
       "13  unlet-hull               structured          1           bfsrs-medium   \n",
       "7   heigh-mope               structured          1           bfsrs-medium   \n",
       "16  mired-bats               structured          1         miprov2-medium   \n",
       "8   kooky-choc               structured          1         miprov2-medium   \n",
       "22  zippy-cane               structured          1          miprov2-light   \n",
       "10  soupy-beak               structured          1          miprov2-light   \n",
       "17  shoal-dolt               structured          1          miprov2-light   \n",
       "21  group-nuke               structured          1          miprov2-light   \n",
       "5   myoid-kefs               structured          1          miprov2-light   \n",
       "23  sated-pond               structured          1                   noop   \n",
       "6   butch-keek               structured          1                   noop   \n",
       "14  minim-rods               structured          1                   noop   \n",
       "11  sonic-doll               structured          1                   noop   \n",
       "12        None               structured          1                   noop   \n",
       "18        None               structured          1                   noop   \n",
       "25  round-duff                      sft       tiny                   noop   \n",
       "\n",
       "   params.lm.model  params.lm.temperature  metrics.exact.precision  \\\n",
       "24      llama-3-8b                    0.0                 1.000000   \n",
       "1   llama-3-8b-sft                    0.0                 0.945660   \n",
       "2   llama-3-8b-sft                    0.0                 0.826799   \n",
       "0   llama-3-8b-sft                    0.0                 0.630100   \n",
       "19    qwen-2.5-32b                    0.0                 0.366102   \n",
       "4     qwen-2.5-32b                    0.0                 0.377839   \n",
       "3       llama-3-8b                    0.0                 0.320626   \n",
       "20      llama-3-8b                    0.0                 0.270941   \n",
       "15      llama-3-8b                    0.0                 0.280462   \n",
       "9       llama-3-8b                    0.5                 0.274224   \n",
       "13      llama-3-8b                    0.0                 0.255153   \n",
       "7       llama-3-8b                    0.5                 0.251933   \n",
       "16      llama-3-8b                    0.0                 0.250988   \n",
       "8       llama-3-8b                    0.5                 0.230381   \n",
       "22      llama-3-8b                    0.0                 0.133240   \n",
       "10      llama-3-8b                    0.5                 0.156149   \n",
       "17      llama-3-8b                    0.0                 0.164665   \n",
       "21    qwen-2.5-32b                    0.0                 0.064546   \n",
       "5     qwen-2.5-32b                    0.0                 0.072078   \n",
       "23    qwen-2.5-32b                    0.0                 0.020862   \n",
       "6     qwen-2.5-32b                    0.0                 0.016973   \n",
       "14      llama-3-8b                    0.0                 0.018212   \n",
       "11      llama-3-8b                    0.5                 0.018026   \n",
       "12      llama-3-8b                    0.0                 0.014586   \n",
       "18      llama-3-8b                    0.0                 0.014586   \n",
       "25  llama-3-8b-sft                    0.0                 0.076155   \n",
       "\n",
       "    metrics.exact.recall  metrics.exact.f1  metrics.fuzzy.precision  \\\n",
       "24              1.000000          1.000000                 1.000000   \n",
       "1               0.939192          0.941871                 0.980038   \n",
       "2               0.806647          0.814956                 0.942006   \n",
       "0               0.622543          0.623483                 0.850379   \n",
       "19              0.358353          0.361248                 0.793954   \n",
       "4               0.367084          0.370645                 0.797541   \n",
       "3               0.319126          0.318514                 0.698233   \n",
       "20              0.263430          0.266274                 0.686891   \n",
       "15              0.275396          0.276618                 0.676080   \n",
       "9               0.268814          0.269906                 0.666549   \n",
       "13              0.246698          0.249767                 0.651775   \n",
       "7               0.243802          0.246764                 0.650937   \n",
       "16              0.233233          0.240662                 0.653248   \n",
       "8               0.214486          0.220995                 0.643391   \n",
       "22              0.133156          0.132834                 0.588515   \n",
       "10              0.156003          0.155215                 0.562983   \n",
       "17              0.159790          0.161087                 0.549267   \n",
       "21              0.064266          0.064222                 0.530839   \n",
       "5               0.069922          0.070684                 0.532639   \n",
       "23              0.020312          0.020562                 0.455415   \n",
       "6               0.016721          0.016769                 0.447680   \n",
       "14              0.017030          0.017500                 0.356735   \n",
       "11              0.016793          0.017272                 0.355650   \n",
       "12              0.013411          0.013894                 0.298027   \n",
       "18              0.013411          0.013894                 0.298027   \n",
       "25              0.079555          0.074850                 0.253334   \n",
       "\n",
       "    metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "24              1.000000          1.000000  \n",
       "1               0.973275          0.976060  \n",
       "2               0.920719          0.929080  \n",
       "0               0.847531          0.844171  \n",
       "19              0.783383          0.786429  \n",
       "4               0.779191          0.783746  \n",
       "3               0.695948          0.693846  \n",
       "20              0.661890          0.671487  \n",
       "15              0.664274          0.666510  \n",
       "9               0.656943          0.657637  \n",
       "13              0.629756          0.637432  \n",
       "7               0.628296          0.636171  \n",
       "16              0.607018          0.625459  \n",
       "8               0.597861          0.615783  \n",
       "22              0.593496          0.588394  \n",
       "10              0.569753          0.562845  \n",
       "17              0.538236          0.540178  \n",
       "21              0.524796          0.526424  \n",
       "5               0.523590          0.525673  \n",
       "23              0.439280          0.445118  \n",
       "6               0.430505          0.436040  \n",
       "14              0.335013          0.341740  \n",
       "11              0.339312          0.340013  \n",
       "12              0.273680          0.282035  \n",
       "18              0.273680          0.282035  \n",
       "25              0.248191          0.237905  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['name', 'params.program.prompting', 'params.run', 'params.train.optimizer', 'params.lm.model', 'params.lm.temperature', *metric_cols]].sort_values(by='metrics.fuzzy.f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
