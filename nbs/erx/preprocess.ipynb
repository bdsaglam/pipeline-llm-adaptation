{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_tuple(x):\n",
    "    return tuple(sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'commit': 'workspace',\n",
       " 'id': 'workspace',\n",
       " 'name': None,\n",
       " 'params': {'task': 'erx',\n",
       "  'train': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'train[:100]'},\n",
       "   'optimizer': 'noop',\n",
       "   'ensemble': 'no'},\n",
       "  'evaluation': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'dev[:1000]'}},\n",
       "  'program': {'prompting': 'structured'},\n",
       "  'lm': {'model': 'llama-3-8b', 'temperature': 0.0},\n",
       "  'run': 1},\n",
       " 'metrics': {'exact.precision': 0.014585968840764236,\n",
       "  'exact.recall': 0.013411106866989222,\n",
       "  'exact.f1': 0.013893968089212146,\n",
       "  'fuzzy.precision': 0.2980273675422333,\n",
       "  'fuzzy.recall': 0.2736804602675239,\n",
       "  'fuzzy.f1': 0.28203483319061007}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapt.dvc import load_experiments\n",
    "\n",
    "filepaths = list(Path(\"../../tmp/erx/\").glob(\"*.json\"))\n",
    "experiments = [exp for fp in filepaths for exp in load_experiments(fp)]\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 experiments before preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>...</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a95fd4dc54ea708f0f7421b291c9ec0e1c8f550</td>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10018c1a534cbb1bb093856fe741782b063885d5</td>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf</td>\n",
       "      <td>irony-gust</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38621dd5eb7f657d0ed4c3060ec1bfdaab830cda</td>\n",
       "      <td>outer-ring</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>207289e5a394e3f9ae82cf08aea3d2ca07e190ba</td>\n",
       "      <td>moral-prof</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>e20f45a313f10b09f83c05fdb44f275d52da7799</td>\n",
       "      <td>spicy-teff</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8af6e338f987cfa912d7ee566a61bd24f956fd7c</td>\n",
       "      <td>epoxy-dele</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>c4c203b34fff9acc3052b01148457799d70463a8</td>\n",
       "      <td>girly-cuss</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10018c1a534cbb1bb093856fe741782b063885d5</td>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf</td>\n",
       "      <td>irony-gust</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>38621dd5eb7f657d0ed4c3060ec1bfdaab830cda</td>\n",
       "      <td>outer-ring</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>207289e5a394e3f9ae82cf08aea3d2ca07e190ba</td>\n",
       "      <td>moral-prof</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>high</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>e20f45a313f10b09f83c05fdb44f275d52da7799</td>\n",
       "      <td>spicy-teff</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8af6e338f987cfa912d7ee566a61bd24f956fd7c</td>\n",
       "      <td>epoxy-dele</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>c4c203b34fff9acc3052b01148457799d70463a8</td>\n",
       "      <td>girly-cuss</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58c71da3a6cb00c3bf59c04a8b3dae22395f9493</td>\n",
       "      <td>master</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6f84f2616434f0cb73f78dd99349821288535df6</td>\n",
       "      <td>metal-pons</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.377839</td>\n",
       "      <td>0.367084</td>\n",
       "      <td>0.370645</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>0.783746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>8db0681d601021cfecaa922e7a118c7afa21a0fa</td>\n",
       "      <td>crumb-geum</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.451251</td>\n",
       "      <td>0.434675</td>\n",
       "      <td>0.437976</td>\n",
       "      <td>0.762150</td>\n",
       "      <td>0.740962</td>\n",
       "      <td>0.742936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>914f4e695eca42802fb2d2b3ab2233cf979773a6</td>\n",
       "      <td>myoid-kefs</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.070684</td>\n",
       "      <td>0.532639</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>0.525673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6d745e03f12c22dca0275b04496e83e8feb903a7</td>\n",
       "      <td>butch-keek</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.447680</td>\n",
       "      <td>0.430505</td>\n",
       "      <td>0.436040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7dc4936294d1dddb12f28ce17518f7c3088ae0cf</td>\n",
       "      <td>master</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ef88ff700af333e8e7079721be6cb75e37941bf7</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>007ce25205955e8faab9b90554c4419fa816612b</td>\n",
       "      <td>heigh-mope</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251933</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.246764</td>\n",
       "      <td>0.650937</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.636171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>110f9f2a1457105cf30b2ac946f87257f8efd22a</td>\n",
       "      <td>kooky-choc</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230381</td>\n",
       "      <td>0.214486</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>0.643391</td>\n",
       "      <td>0.597861</td>\n",
       "      <td>0.615783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>dfbdcc8613644d8ae30ed665cd8fae32ee736c6b</td>\n",
       "      <td>modal-huck</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.268814</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.666549</td>\n",
       "      <td>0.656943</td>\n",
       "      <td>0.657637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>e5fc13ef2ba64b4c382668e5c83a0c78f95aa519</td>\n",
       "      <td>soupy-beak</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.156003</td>\n",
       "      <td>0.155215</td>\n",
       "      <td>0.562983</td>\n",
       "      <td>0.569753</td>\n",
       "      <td>0.562845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4857b673e9d9ea6572cde3023e88641ee13b86eb</td>\n",
       "      <td>outer-bree</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>f60ee9a88afff0a1dec5fd1ee7fcfaba02ffaf7b</td>\n",
       "      <td>sonic-doll</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>0.339312</td>\n",
       "      <td>0.340013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0eb39919067db6bf4119d30035287995196816b6</td>\n",
       "      <td>laigh-wads</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>140cfb24cde7906f54e169acb128aea2ec9746f7</td>\n",
       "      <td>acred-care</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>fb27b1c0b1a1b56970d34ff4648c11e7635a9336</td>\n",
       "      <td>boric-bunt</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>726315f09e015c0871bdeec1f359320045e3115b</td>\n",
       "      <td>cadgy-friz</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ed74cb3591c364bf44234fe0c76b1a493846c358</td>\n",
       "      <td>alone-mesh</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7</td>\n",
       "      <td>slack-poss</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>f939aab33f08dd257d0e54960c02affa57ff8733</td>\n",
       "      <td>group-nuke</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>d82bf43700c686be11581eceae44b54b04b1299c</td>\n",
       "      <td>zippy-cane</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>6600c85835c4d5dd5ff822f952838e0eaf0351c2</td>\n",
       "      <td>sated-pond</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          id        name params.task  \\\n",
       "0                                  workspace        None         erx   \n",
       "1   8a95fd4dc54ea708f0f7421b291c9ec0e1c8f550  lathy-jaws         erx   \n",
       "2   10018c1a534cbb1bb093856fe741782b063885d5  bluff-dita         erx   \n",
       "3   d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf  irony-gust         erx   \n",
       "4   38621dd5eb7f657d0ed4c3060ec1bfdaab830cda  outer-ring         erx   \n",
       "5   207289e5a394e3f9ae82cf08aea3d2ca07e190ba  moral-prof         erx   \n",
       "6   e20f45a313f10b09f83c05fdb44f275d52da7799  spicy-teff         erx   \n",
       "7   8af6e338f987cfa912d7ee566a61bd24f956fd7c  epoxy-dele         erx   \n",
       "8   c4c203b34fff9acc3052b01148457799d70463a8  girly-cuss         erx   \n",
       "9                                  workspace        None         erx   \n",
       "10  10018c1a534cbb1bb093856fe741782b063885d5  bluff-dita         erx   \n",
       "11  d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf  irony-gust         erx   \n",
       "12  38621dd5eb7f657d0ed4c3060ec1bfdaab830cda  outer-ring         erx   \n",
       "13  207289e5a394e3f9ae82cf08aea3d2ca07e190ba  moral-prof         erx   \n",
       "14  e20f45a313f10b09f83c05fdb44f275d52da7799  spicy-teff         erx   \n",
       "15  8af6e338f987cfa912d7ee566a61bd24f956fd7c  epoxy-dele         erx   \n",
       "16  c4c203b34fff9acc3052b01148457799d70463a8  girly-cuss         erx   \n",
       "17                                 workspace        None         erx   \n",
       "18  58c71da3a6cb00c3bf59c04a8b3dae22395f9493      master         erx   \n",
       "19  6f84f2616434f0cb73f78dd99349821288535df6  metal-pons         erx   \n",
       "20  8db0681d601021cfecaa922e7a118c7afa21a0fa  crumb-geum         erx   \n",
       "21  914f4e695eca42802fb2d2b3ab2233cf979773a6  myoid-kefs         erx   \n",
       "22  6d745e03f12c22dca0275b04496e83e8feb903a7  butch-keek         erx   \n",
       "23                                 workspace        None         erx   \n",
       "24  7dc4936294d1dddb12f28ce17518f7c3088ae0cf      master         erx   \n",
       "25  ef88ff700af333e8e7079721be6cb75e37941bf7        None         erx   \n",
       "26  007ce25205955e8faab9b90554c4419fa816612b  heigh-mope         erx   \n",
       "27  110f9f2a1457105cf30b2ac946f87257f8efd22a  kooky-choc         erx   \n",
       "28  dfbdcc8613644d8ae30ed665cd8fae32ee736c6b  modal-huck         erx   \n",
       "29  e5fc13ef2ba64b4c382668e5c83a0c78f95aa519  soupy-beak         erx   \n",
       "30  4857b673e9d9ea6572cde3023e88641ee13b86eb  outer-bree         erx   \n",
       "31  f60ee9a88afff0a1dec5fd1ee7fcfaba02ffaf7b  sonic-doll         erx   \n",
       "32  0eb39919067db6bf4119d30035287995196816b6  laigh-wads         erx   \n",
       "33  140cfb24cde7906f54e169acb128aea2ec9746f7  acred-care         erx   \n",
       "34  fb27b1c0b1a1b56970d34ff4648c11e7635a9336  boric-bunt         erx   \n",
       "35  726315f09e015c0871bdeec1f359320045e3115b  cadgy-friz         erx   \n",
       "36                                 workspace        None         erx   \n",
       "37  ed74cb3591c364bf44234fe0c76b1a493846c358  alone-mesh         erx   \n",
       "38  fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7  slack-poss         erx   \n",
       "39  f939aab33f08dd257d0e54960c02affa57ff8733  group-nuke         erx   \n",
       "40  d82bf43700c686be11581eceae44b54b04b1299c  zippy-cane         erx   \n",
       "41  6600c85835c4d5dd5ff822f952838e0eaf0351c2  sated-pond         erx   \n",
       "\n",
       "      params.train.dataset.path params.train.dataset.name  \\\n",
       "0   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "2   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "3   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "4   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "5   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "6   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "7   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "8   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "9   bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "10  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "11  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "12  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "13  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "14  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "15  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "16  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "17  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "18  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "19  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "20  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "21  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "22  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "23  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "24  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "25  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "26  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "27  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "28  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "29  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "30  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "31  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "32  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "33  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "34  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "35  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "36  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "37  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "38  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "39  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "40  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "41  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "   params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                 train[:100]                   noop                    no   \n",
       "1                 train[:100]                   noop                    no   \n",
       "2                 train[:100]             bfsrs-high                    no   \n",
       "3                 train[:100]         miprov2-medium                    no   \n",
       "4                 train[:100]           bfsrs-medium                    no   \n",
       "5                 train[:100]                   noop                    no   \n",
       "6                 train[:100]                   noop                    no   \n",
       "7                 train[:100]          miprov2-light                    no   \n",
       "8                 train[:100]                   noop                    no   \n",
       "9                 train[:100]                   noop                    no   \n",
       "10                train[:100]             bfsrs-high                    no   \n",
       "11                train[:100]         miprov2-medium                    no   \n",
       "12                train[:100]           bfsrs-medium                    no   \n",
       "13                train[:100]                   noop                    no   \n",
       "14                train[:100]                   noop                    no   \n",
       "15                train[:100]          miprov2-light                    no   \n",
       "16                train[:100]                   noop                    no   \n",
       "17                train[:100]                   noop                    no   \n",
       "18                train[:100]                   noop                    no   \n",
       "19                train[:100]           bfsrs-medium                    no   \n",
       "20                train[:100]                   noop                    no   \n",
       "21                train[:100]          miprov2-light                    no   \n",
       "22                train[:100]                   noop                    no   \n",
       "23                train[:100]                   noop                    no   \n",
       "24                train[:100]                   noop                    no   \n",
       "25                train[:100]                   noop                    no   \n",
       "26                train[:100]           bfsrs-medium                    no   \n",
       "27                train[:100]         miprov2-medium                    no   \n",
       "28                train[:100]             bfsrs-high                    no   \n",
       "29                train[:100]          miprov2-light                    no   \n",
       "30                train[:100]                   noop                    no   \n",
       "31                train[:100]                   noop                    no   \n",
       "32                train[:100]           bfsrs-medium                    no   \n",
       "33                train[:100]             bfsrs-high                    no   \n",
       "34                train[:100]         miprov2-medium                    no   \n",
       "35                train[:100]          miprov2-light                    no   \n",
       "36                train[:100]                   noop                    no   \n",
       "37                train[:100]           bfsrs-medium                    no   \n",
       "38                train[:100]           bfsrs-medium                    no   \n",
       "39                train[:100]          miprov2-light                    no   \n",
       "40                train[:100]          miprov2-light                    no   \n",
       "41                train[:100]                   noop                    no   \n",
       "\n",
       "   params.evaluation.dataset.path params.evaluation.dataset.name  ...  \\\n",
       "0     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "1     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "2     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "3     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "4     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "5     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "6     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "7     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "8     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "9     bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "10    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "11    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "12    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "13    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "14    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "15    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "16    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "17    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "18    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "19    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "20    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "21    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "22    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "23    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "24    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "25    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "26    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "27    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "28    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "29    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "30    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "31    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "32    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "33    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "34    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "35    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "36    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "37    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "38    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "39    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "40    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "41    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "\n",
       "   params.program.prompting params.lm.model params.lm.temperature  params.run  \\\n",
       "0                structured      llama-3-8b                   0.0           1   \n",
       "1                       sft  llama-3-8b-sft                   0.0         low   \n",
       "2                structured      llama-3-8b                   0.0           1   \n",
       "3                structured      llama-3-8b                   0.0           1   \n",
       "4                structured      llama-3-8b                   0.0           1   \n",
       "5                       sft  llama-3-8b-sft                   0.0        high   \n",
       "6                       sft  llama-3-8b-sft                   0.0      medium   \n",
       "7                structured      llama-3-8b                   0.0           1   \n",
       "8                structured      llama-3-8b                   0.0           1   \n",
       "9                structured      llama-3-8b                   0.0           1   \n",
       "10               structured      llama-3-8b                   0.0           1   \n",
       "11               structured      llama-3-8b                   0.0           1   \n",
       "12               structured      llama-3-8b                   0.0           1   \n",
       "13                      sft  llama-3-8b-sft                   0.0        high   \n",
       "14                      sft  llama-3-8b-sft                   0.0      medium   \n",
       "15               structured      llama-3-8b                   0.0           1   \n",
       "16               structured      llama-3-8b                   0.0           1   \n",
       "17               structured      llama-3-8b                   0.0           1   \n",
       "18               structured      llama-3-8b                   0.0           1   \n",
       "19               structured    qwen-2.5-32b                   0.0           1   \n",
       "20                      sft      llama-3-8b                   0.0           1   \n",
       "21                      NaN    qwen-2.5-32b                   0.0           1   \n",
       "22                      NaN    qwen-2.5-32b                   0.0           1   \n",
       "23               structured      llama-3-8b                   0.0           1   \n",
       "24               structured      llama-3-8b                   0.0           1   \n",
       "25               structured      llama-3-8b                   0.0           1   \n",
       "26               structured      llama-3-8b                   0.5           1   \n",
       "27               structured      llama-3-8b                   0.5           1   \n",
       "28               structured      llama-3-8b                   0.5           1   \n",
       "29               structured      llama-3-8b                   0.5           1   \n",
       "30               structured      llama-3-8b                   0.0           1   \n",
       "31               structured      llama-3-8b                   0.5           1   \n",
       "32               structured      llama-3-8b                   0.0           1   \n",
       "33               structured      llama-3-8b                   0.0           1   \n",
       "34               structured      llama-3-8b                   0.0           1   \n",
       "35               structured      llama-3-8b                   0.0           1   \n",
       "36                      NaN      llama-3-8b                   0.0           1   \n",
       "37                      NaN    qwen-2.5-32b                   0.0           1   \n",
       "38                      NaN      llama-3-8b                   0.0           1   \n",
       "39                      NaN    qwen-2.5-32b                   0.0           1   \n",
       "40                      NaN      llama-3-8b                   0.0           1   \n",
       "41                      NaN    qwen-2.5-32b                   0.0           1   \n",
       "\n",
       "   metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "0                 0.014586              0.013411          0.013894   \n",
       "1                 0.630100              0.622543          0.623483   \n",
       "2                 0.280462              0.275396          0.276618   \n",
       "3                 0.250988              0.233233          0.240662   \n",
       "4                 0.255153              0.246698          0.249767   \n",
       "5                 0.945660              0.939192          0.941871   \n",
       "6                 0.826799              0.806647          0.814956   \n",
       "7                 0.164665              0.159790          0.161087   \n",
       "8                 0.018212              0.017030          0.017500   \n",
       "9                 0.014586              0.013411          0.013894   \n",
       "10                0.280462              0.275396          0.276618   \n",
       "11                0.250988              0.233233          0.240662   \n",
       "12                0.255153              0.246698          0.249767   \n",
       "13                0.945660              0.939192          0.941871   \n",
       "14                0.826799              0.806647          0.814956   \n",
       "15                0.164665              0.159790          0.161087   \n",
       "16                0.018212              0.017030          0.017500   \n",
       "17                0.014586              0.013411          0.013894   \n",
       "18                0.014586              0.013411          0.013894   \n",
       "19                0.377839              0.367084          0.370645   \n",
       "20                0.451251              0.434675          0.437976   \n",
       "21                0.072078              0.069922          0.070684   \n",
       "22                0.016973              0.016721          0.016769   \n",
       "23                0.014586              0.013411          0.013894   \n",
       "24                0.014586              0.013411          0.013894   \n",
       "25                0.014586              0.013411          0.013894   \n",
       "26                0.251933              0.243802          0.246764   \n",
       "27                0.230381              0.214486          0.220995   \n",
       "28                0.274224              0.268814          0.269906   \n",
       "29                0.156149              0.156003          0.155215   \n",
       "30                0.018212              0.017030          0.017500   \n",
       "31                0.018026              0.016793          0.017272   \n",
       "32                0.255153              0.246698          0.249767   \n",
       "33                0.280462              0.275396          0.276618   \n",
       "34                0.250988              0.233233          0.240662   \n",
       "35                0.164665              0.159790          0.161087   \n",
       "36                0.014586              0.013411          0.013894   \n",
       "37                0.366102              0.358353          0.361248   \n",
       "38                0.270941              0.263430          0.266274   \n",
       "39                0.064546              0.064266          0.064222   \n",
       "40                0.133240              0.133156          0.132834   \n",
       "41                0.020862              0.020312          0.020562   \n",
       "\n",
       "    metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "0                  0.298027              0.273680          0.282035  \n",
       "1                  0.850379              0.847531          0.844171  \n",
       "2                  0.676080              0.664274          0.666510  \n",
       "3                  0.653248              0.607018          0.625459  \n",
       "4                  0.651775              0.629756          0.637432  \n",
       "5                  0.980038              0.973275          0.976060  \n",
       "6                  0.942006              0.920719          0.929080  \n",
       "7                  0.549267              0.538236          0.540178  \n",
       "8                  0.356735              0.335013          0.341740  \n",
       "9                  0.298027              0.273680          0.282035  \n",
       "10                 0.676080              0.664274          0.666510  \n",
       "11                 0.653248              0.607018          0.625459  \n",
       "12                 0.651775              0.629756          0.637432  \n",
       "13                 0.980038              0.973275          0.976060  \n",
       "14                 0.942006              0.920719          0.929080  \n",
       "15                 0.549267              0.538236          0.540178  \n",
       "16                 0.356735              0.335013          0.341740  \n",
       "17                 0.298027              0.273680          0.282035  \n",
       "18                 0.298027              0.273680          0.282035  \n",
       "19                 0.797541              0.779191          0.783746  \n",
       "20                 0.762150              0.740962          0.742936  \n",
       "21                 0.532639              0.523590          0.525673  \n",
       "22                 0.447680              0.430505          0.436040  \n",
       "23                 0.298027              0.273680          0.282035  \n",
       "24                 0.298027              0.273680          0.282035  \n",
       "25                 0.298027              0.273680          0.282035  \n",
       "26                 0.650937              0.628296          0.636171  \n",
       "27                 0.643391              0.597861          0.615783  \n",
       "28                 0.666549              0.656943          0.657637  \n",
       "29                 0.562983              0.569753          0.562845  \n",
       "30                 0.356735              0.335013          0.341740  \n",
       "31                 0.355650              0.339312          0.340013  \n",
       "32                 0.651775              0.629756          0.637432  \n",
       "33                 0.676080              0.664274          0.666510  \n",
       "34                 0.653248              0.607018          0.625459  \n",
       "35                 0.549267              0.538236          0.540178  \n",
       "36                 0.298027              0.273680          0.282035  \n",
       "37                 0.793954              0.783383          0.786429  \n",
       "38                 0.686891              0.661890          0.671487  \n",
       "39                 0.530839              0.524796          0.526424  \n",
       "40                 0.588515              0.593496          0.588394  \n",
       "41                 0.455415              0.439280          0.445118  \n",
       "\n",
       "[42 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(experiments).drop(columns=[\"commit\"])\n",
    "print(f\"{len(df)} experiments before preprocessing\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'params.program.prompting' not in df.columns:\n",
    "    df['params.program.prompting'] = 'structured'\n",
    "df['params.program.prompting'] = df['params.program.prompting'].fillna('structured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 experiments after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>...</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8a95fd4dc54ea708f0f7421b291c9ec0e1c8f550</td>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>low</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10018c1a534cbb1bb093856fe741782b063885d5</td>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf</td>\n",
       "      <td>irony-gust</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38621dd5eb7f657d0ed4c3060ec1bfdaab830cda</td>\n",
       "      <td>outer-ring</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>...</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        name params.task  \\\n",
       "0                                 workspace        None         erx   \n",
       "1  8a95fd4dc54ea708f0f7421b291c9ec0e1c8f550  lathy-jaws         erx   \n",
       "2  10018c1a534cbb1bb093856fe741782b063885d5  bluff-dita         erx   \n",
       "3  d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf  irony-gust         erx   \n",
       "4  38621dd5eb7f657d0ed4c3060ec1bfdaab830cda  outer-ring         erx   \n",
       "\n",
       "     params.train.dataset.path params.train.dataset.name  \\\n",
       "0  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "2  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "3  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "4  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "  params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                train[:100]                   noop                    no   \n",
       "1                train[:100]                   noop                    no   \n",
       "2                train[:100]             bfsrs-high                    no   \n",
       "3                train[:100]         miprov2-medium                    no   \n",
       "4                train[:100]           bfsrs-medium                    no   \n",
       "\n",
       "  params.evaluation.dataset.path params.evaluation.dataset.name  ...  \\\n",
       "0    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "1    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "2    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "3    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "4    bdsaglam/web_nlg-erx-concat                release_v3.0_en  ...   \n",
       "\n",
       "  params.program.prompting params.lm.model params.lm.temperature  params.run  \\\n",
       "0               structured      llama-3-8b                   0.0           1   \n",
       "1                      sft  llama-3-8b-sft                   0.0         low   \n",
       "2               structured      llama-3-8b                   0.0           1   \n",
       "3               structured      llama-3-8b                   0.0           1   \n",
       "4               structured      llama-3-8b                   0.0           1   \n",
       "\n",
       "  metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "0                0.014586              0.013411          0.013894   \n",
       "1                0.630100              0.622543          0.623483   \n",
       "2                0.280462              0.275396          0.276618   \n",
       "3                0.250988              0.233233          0.240662   \n",
       "4                0.255153              0.246698          0.249767   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "0                 0.298027              0.273680          0.282035  \n",
       "1                 0.850379              0.847531          0.844171  \n",
       "2                 0.676080              0.664274          0.666510  \n",
       "3                 0.653248              0.607018          0.625459  \n",
       "4                 0.651775              0.629756          0.637432  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(subset=param_cols + metric_cols, inplace=True, how=\"any\")\n",
    "df.drop_duplicates(subset=param_cols, inplace=True)\n",
    "\n",
    "print(f\"{len(df)} experiments after preprocessing\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- params.task: ['erx']\n",
      "\n",
      "- params.train.dataset.path: ['bdsaglam/web_nlg-erx-concat']\n",
      "\n",
      "- params.train.dataset.name: ['release_v3.0_en']\n",
      "\n",
      "- params.train.dataset.split: ['train[:100]']\n",
      "\n",
      "- params.train.optimizer: ['noop', 'bfsrs-high', 'miprov2-medium', 'bfsrs-medium', 'miprov2-light']\n",
      "\n",
      "- params.train.ensemble: ['no']\n",
      "\n",
      "- params.evaluation.dataset.path: ['bdsaglam/web_nlg-erx-concat']\n",
      "\n",
      "- params.evaluation.dataset.name: ['release_v3.0_en']\n",
      "\n",
      "- params.evaluation.dataset.split: ['dev[:1000]', 'dev', 'dev[:100]']\n",
      "\n",
      "- params.program.prompting: ['structured', 'sft']\n",
      "\n",
      "- params.lm.model: ['llama-3-8b', 'llama-3-8b-sft', 'qwen-2.5-32b']\n",
      "\n",
      "- params.lm.temperature: [np.float64(0.0), np.float64(0.5)]\n",
      "\n",
      "- params.run: [1, 'low', 'high', 'medium']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for col in param_cols:\n",
    "    values = list(df[col].unique())\n",
    "    print(f\"- {col}: {values}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('exps.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup remaining experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_experiment_configs(common_params, varying_params):\n",
    "    # Generate all possible combinations of parameters\n",
    "    varying_params = {**common_params, **varying_params}\n",
    "    keys = varying_params.keys()\n",
    "    values = varying_params.values()\n",
    "    for instance in itertools.product(*values):\n",
    "        yield dict(zip(keys, instance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_all_experiment_configs(common_params: dict, varying_params_list: list[dict]):\n",
    "    for params in varying_params_list:\n",
    "        for exp_config in produce_experiment_configs(common_params, params):\n",
    "            yield exp_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_params = {\n",
    "    \"params.task\": [\"erx\"],\n",
    "    \"params.train.dataset.path\": [\"bdsaglam/web_nlg-erx-concat\"],\n",
    "    \"params.train.dataset.name\": [\"release_v3.0_en\"],\n",
    "    \"params.train.dataset.split\": ['\"train[:100]\"'],\n",
    "    \"params.evaluation.dataset.path\": [\"bdsaglam/web_nlg-erx-concat\"],\n",
    "    \"params.evaluation.dataset.name\": [\"release_v3.0_en\"],\n",
    "    \"params.evaluation.dataset.split\": ['\"dev\"'],\n",
    "    \"params.train.ensemble\": [\n",
    "        \"no\",\n",
    "        # \"yes\",\n",
    "    ],\n",
    "    \"params.lm.temperature\": [\n",
    "        0.0,\n",
    "        # 0.5,\n",
    "        # 0.7,\n",
    "    ],\n",
    "    \"params.run\": [\n",
    "        1,\n",
    "        # 2,\n",
    "        # 3,\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "varying_params_list = [\n",
    "    {\n",
    "        \"params.train.optimizer\": [\n",
    "            \"noop\",\n",
    "            \"bfsrs-medium\",\n",
    "            \"bfsrs-high\",\n",
    "            'bfsrs-ulti',\n",
    "            \"miprov2-light\",\n",
    "            \"miprov2-medium\",\n",
    "        ],\n",
    "        \"params.program.prompting\": [\"structured\"],\n",
    "        \"params.lm.model\": [\n",
    "            \"llama-3-8b\",\n",
    "            # \"qwen-2.5-32b\",\n",
    "        ],\n",
    "    },\n",
    "    # {\n",
    "    #     \"params.train.optimizer\": [\"noop\"],\n",
    "    #     \"params.program.prompting\": [\"sft\"],\n",
    "    #     \"params.lm.model\": [\n",
    "    #         \"llama-3-8b-sft\",\n",
    "    #     ],\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiment configurations\n",
      "['params.task', 'params.train.dataset.path', 'params.train.dataset.name', 'params.train.dataset.split', 'params.evaluation.dataset.path', 'params.evaluation.dataset.name', 'params.evaluation.dataset.split', 'params.train.ensemble', 'params.lm.temperature', 'params.run', 'params.train.optimizer', 'params.program.prompting', 'params.lm.model']\n"
     ]
    }
   ],
   "source": [
    "exp_configs = list(produce_all_experiment_configs(common_params, varying_params_list))\n",
    "target_params = list(exp_configs[0].keys())\n",
    "print(f\"{len(exp_configs)} experiment configurations\")\n",
    "print(target_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing exps: 24\n"
     ]
    }
   ],
   "source": [
    "if len(df):\n",
    "    existing_configs = df[target_params].to_dict(orient=\"records\")\n",
    "    existing_configs[0]\n",
    "else:\n",
    "    existing_configs = []\n",
    "\n",
    "print(\"Existing exps:\", len(existing_configs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 missing configurations\n"
     ]
    }
   ],
   "source": [
    "# find the missing configurations\n",
    "missing_configs = [\n",
    "    dict(kv)\n",
    "    for kv in list(\n",
    "        {tuple(sorted(config.items())) for config in exp_configs}\n",
    "        - {tuple(sorted(config.items())) for config in existing_configs}\n",
    "    )\n",
    "]\n",
    "print(f\"{len(missing_configs)} missing configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_command(exp_config):\n",
    "    lines = [\"dvc exp run --queue\"]\n",
    "    for target_param in target_params:\n",
    "        arg_name = target_param.split(\".\", 1)[-1]\n",
    "        arg_value = exp_config[target_param]\n",
    "        lines.append(f\"-S {arg_name}='{arg_value}'\")\n",
    "\n",
    "    command = \" \\\\\\n    \".join(lines)\n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"run.sh\", \"w\") as f:\n",
    "    f.write(\"#!/bin/sh\\n\\n\")\n",
    "    for exp_config in missing_configs:\n",
    "        f.write(make_command(exp_config))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.run</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moral-prof</td>\n",
       "      <td>sft</td>\n",
       "      <td>high</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spicy-teff</td>\n",
       "      <td>sft</td>\n",
       "      <td>medium</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>sft</td>\n",
       "      <td>low</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>alone-mesh</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>metal-pons</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377839</td>\n",
       "      <td>0.367084</td>\n",
       "      <td>0.370645</td>\n",
       "      <td>0.797541</td>\n",
       "      <td>0.779191</td>\n",
       "      <td>0.783746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>crumb-geum</td>\n",
       "      <td>sft</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451251</td>\n",
       "      <td>0.434675</td>\n",
       "      <td>0.437976</td>\n",
       "      <td>0.762150</td>\n",
       "      <td>0.740962</td>\n",
       "      <td>0.742936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>slack-poss</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>modal-huck</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.274224</td>\n",
       "      <td>0.268814</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.666549</td>\n",
       "      <td>0.656943</td>\n",
       "      <td>0.657637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outer-ring</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>heigh-mope</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.251933</td>\n",
       "      <td>0.243802</td>\n",
       "      <td>0.246764</td>\n",
       "      <td>0.650937</td>\n",
       "      <td>0.628296</td>\n",
       "      <td>0.636171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irony-gust</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kooky-choc</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.230381</td>\n",
       "      <td>0.214486</td>\n",
       "      <td>0.220995</td>\n",
       "      <td>0.643391</td>\n",
       "      <td>0.597861</td>\n",
       "      <td>0.615783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>zippy-cane</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>soupy-beak</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.156149</td>\n",
       "      <td>0.156003</td>\n",
       "      <td>0.155215</td>\n",
       "      <td>0.562983</td>\n",
       "      <td>0.569753</td>\n",
       "      <td>0.562845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epoxy-dele</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>group-nuke</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>myoid-kefs</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072078</td>\n",
       "      <td>0.069922</td>\n",
       "      <td>0.070684</td>\n",
       "      <td>0.532639</td>\n",
       "      <td>0.523590</td>\n",
       "      <td>0.525673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sated-pond</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>butch-keek</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.016721</td>\n",
       "      <td>0.016769</td>\n",
       "      <td>0.447680</td>\n",
       "      <td>0.430505</td>\n",
       "      <td>0.436040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>girly-cuss</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>sonic-doll</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.016793</td>\n",
       "      <td>0.017272</td>\n",
       "      <td>0.355650</td>\n",
       "      <td>0.339312</td>\n",
       "      <td>0.340013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>None</td>\n",
       "      <td>structured</td>\n",
       "      <td>1</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          name params.program.prompting params.run params.train.optimizer  \\\n",
       "5   moral-prof                      sft       high                   noop   \n",
       "6   spicy-teff                      sft     medium                   noop   \n",
       "1   lathy-jaws                      sft        low                   noop   \n",
       "37  alone-mesh               structured          1           bfsrs-medium   \n",
       "19  metal-pons               structured          1           bfsrs-medium   \n",
       "20  crumb-geum                      sft          1                   noop   \n",
       "38  slack-poss               structured          1           bfsrs-medium   \n",
       "2   bluff-dita               structured          1             bfsrs-high   \n",
       "28  modal-huck               structured          1             bfsrs-high   \n",
       "4   outer-ring               structured          1           bfsrs-medium   \n",
       "26  heigh-mope               structured          1           bfsrs-medium   \n",
       "3   irony-gust               structured          1         miprov2-medium   \n",
       "27  kooky-choc               structured          1         miprov2-medium   \n",
       "40  zippy-cane               structured          1          miprov2-light   \n",
       "29  soupy-beak               structured          1          miprov2-light   \n",
       "7   epoxy-dele               structured          1          miprov2-light   \n",
       "39  group-nuke               structured          1          miprov2-light   \n",
       "21  myoid-kefs               structured          1          miprov2-light   \n",
       "41  sated-pond               structured          1                   noop   \n",
       "22  butch-keek               structured          1                   noop   \n",
       "8   girly-cuss               structured          1                   noop   \n",
       "31  sonic-doll               structured          1                   noop   \n",
       "0         None               structured          1                   noop   \n",
       "36        None               structured          1                   noop   \n",
       "\n",
       "   params.lm.model  params.lm.temperature  metrics.exact.precision  \\\n",
       "5   llama-3-8b-sft                    0.0                 0.945660   \n",
       "6   llama-3-8b-sft                    0.0                 0.826799   \n",
       "1   llama-3-8b-sft                    0.0                 0.630100   \n",
       "37    qwen-2.5-32b                    0.0                 0.366102   \n",
       "19    qwen-2.5-32b                    0.0                 0.377839   \n",
       "20      llama-3-8b                    0.0                 0.451251   \n",
       "38      llama-3-8b                    0.0                 0.270941   \n",
       "2       llama-3-8b                    0.0                 0.280462   \n",
       "28      llama-3-8b                    0.5                 0.274224   \n",
       "4       llama-3-8b                    0.0                 0.255153   \n",
       "26      llama-3-8b                    0.5                 0.251933   \n",
       "3       llama-3-8b                    0.0                 0.250988   \n",
       "27      llama-3-8b                    0.5                 0.230381   \n",
       "40      llama-3-8b                    0.0                 0.133240   \n",
       "29      llama-3-8b                    0.5                 0.156149   \n",
       "7       llama-3-8b                    0.0                 0.164665   \n",
       "39    qwen-2.5-32b                    0.0                 0.064546   \n",
       "21    qwen-2.5-32b                    0.0                 0.072078   \n",
       "41    qwen-2.5-32b                    0.0                 0.020862   \n",
       "22    qwen-2.5-32b                    0.0                 0.016973   \n",
       "8       llama-3-8b                    0.0                 0.018212   \n",
       "31      llama-3-8b                    0.5                 0.018026   \n",
       "0       llama-3-8b                    0.0                 0.014586   \n",
       "36      llama-3-8b                    0.0                 0.014586   \n",
       "\n",
       "    metrics.exact.recall  metrics.exact.f1  metrics.fuzzy.precision  \\\n",
       "5               0.939192          0.941871                 0.980038   \n",
       "6               0.806647          0.814956                 0.942006   \n",
       "1               0.622543          0.623483                 0.850379   \n",
       "37              0.358353          0.361248                 0.793954   \n",
       "19              0.367084          0.370645                 0.797541   \n",
       "20              0.434675          0.437976                 0.762150   \n",
       "38              0.263430          0.266274                 0.686891   \n",
       "2               0.275396          0.276618                 0.676080   \n",
       "28              0.268814          0.269906                 0.666549   \n",
       "4               0.246698          0.249767                 0.651775   \n",
       "26              0.243802          0.246764                 0.650937   \n",
       "3               0.233233          0.240662                 0.653248   \n",
       "27              0.214486          0.220995                 0.643391   \n",
       "40              0.133156          0.132834                 0.588515   \n",
       "29              0.156003          0.155215                 0.562983   \n",
       "7               0.159790          0.161087                 0.549267   \n",
       "39              0.064266          0.064222                 0.530839   \n",
       "21              0.069922          0.070684                 0.532639   \n",
       "41              0.020312          0.020562                 0.455415   \n",
       "22              0.016721          0.016769                 0.447680   \n",
       "8               0.017030          0.017500                 0.356735   \n",
       "31              0.016793          0.017272                 0.355650   \n",
       "0               0.013411          0.013894                 0.298027   \n",
       "36              0.013411          0.013894                 0.298027   \n",
       "\n",
       "    metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "5               0.973275          0.976060  \n",
       "6               0.920719          0.929080  \n",
       "1               0.847531          0.844171  \n",
       "37              0.783383          0.786429  \n",
       "19              0.779191          0.783746  \n",
       "20              0.740962          0.742936  \n",
       "38              0.661890          0.671487  \n",
       "2               0.664274          0.666510  \n",
       "28              0.656943          0.657637  \n",
       "4               0.629756          0.637432  \n",
       "26              0.628296          0.636171  \n",
       "3               0.607018          0.625459  \n",
       "27              0.597861          0.615783  \n",
       "40              0.593496          0.588394  \n",
       "29              0.569753          0.562845  \n",
       "7               0.538236          0.540178  \n",
       "39              0.524796          0.526424  \n",
       "21              0.523590          0.525673  \n",
       "41              0.439280          0.445118  \n",
       "22              0.430505          0.436040  \n",
       "8               0.335013          0.341740  \n",
       "31              0.339312          0.340013  \n",
       "0               0.273680          0.282035  \n",
       "36              0.273680          0.282035  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['name', 'params.program.prompting', 'params.run', 'params.train.optimizer', 'params.lm.model', 'params.lm.temperature', *metric_cols]].sort_values(by='metrics.fuzzy.f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
