{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiments\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'commit': 'workspace',\n",
       " 'id': 'workspace',\n",
       " 'name': None,\n",
       " 'params': {'task': 'erx',\n",
       "  'train': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'train[:100]'},\n",
       "   'optimizer': 'noop',\n",
       "   'ensemble': 'no'},\n",
       "  'evaluation': {'dataset': {'path': 'bdsaglam/web_nlg-erx-concat',\n",
       "    'name': 'release_v3.0_en',\n",
       "    'split': 'dev[:100]'}},\n",
       "  'lm': {'model': 'llama-3-8b', 'temperature': 0.0},\n",
       "  'run': 1},\n",
       " 'metrics': {'exact.precision': 0.014585968840764236,\n",
       "  'exact.recall': 0.013411106866989222,\n",
       "  'exact.f1': 0.013893968089212146,\n",
       "  'fuzzy.precision': 0.2980273675422333,\n",
       "  'fuzzy.recall': 0.2736804602675239,\n",
       "  'fuzzy.f1': 0.28203483319061007}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from adapt.dvc import load_experiments\n",
    "\n",
    "filepaths = list(Path(\"../../tmp/erx/\").glob(\"*.json\"))\n",
    "experiments = [exp for fp in filepaths for exp in load_experiments(fp)]\n",
    "print(f\"{len(experiments)} experiments\")\n",
    "experiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiments before preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>params.evaluation.dataset.split</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed74cb3591c364bf44234fe0c76b1a493846c358</td>\n",
       "      <td>alone-mesh</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7</td>\n",
       "      <td>slack-poss</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f939aab33f08dd257d0e54960c02affa57ff8733</td>\n",
       "      <td>group-nuke</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d82bf43700c686be11581eceae44b54b04b1299c</td>\n",
       "      <td>zippy-cane</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6600c85835c4d5dd5ff822f952838e0eaf0351c2</td>\n",
       "      <td>sated-pond</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        name params.task  \\\n",
       "0                                 workspace        None         erx   \n",
       "1  ed74cb3591c364bf44234fe0c76b1a493846c358  alone-mesh         erx   \n",
       "2  fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7  slack-poss         erx   \n",
       "3  f939aab33f08dd257d0e54960c02affa57ff8733  group-nuke         erx   \n",
       "4  d82bf43700c686be11581eceae44b54b04b1299c  zippy-cane         erx   \n",
       "5  6600c85835c4d5dd5ff822f952838e0eaf0351c2  sated-pond         erx   \n",
       "\n",
       "     params.train.dataset.path params.train.dataset.name  \\\n",
       "0  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "2  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "3  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "4  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "5  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "  params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                train[:100]                   noop                    no   \n",
       "1                train[:100]           bfsrs-medium                    no   \n",
       "2                train[:100]           bfsrs-medium                    no   \n",
       "3                train[:100]          miprov2-light                    no   \n",
       "4                train[:100]          miprov2-light                    no   \n",
       "5                train[:100]                   noop                    no   \n",
       "\n",
       "  params.evaluation.dataset.path params.evaluation.dataset.name  \\\n",
       "0    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "1    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "2    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "3    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "4    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "5    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "\n",
       "  params.evaluation.dataset.split params.lm.model  params.lm.temperature  \\\n",
       "0                       dev[:100]      llama-3-8b                    0.0   \n",
       "1                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "2                       dev[:100]      llama-3-8b                    0.0   \n",
       "3                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "4                       dev[:100]      llama-3-8b                    0.0   \n",
       "5                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "\n",
       "   params.run  metrics.exact.precision  metrics.exact.recall  \\\n",
       "0           1                 0.014586              0.013411   \n",
       "1           1                 0.366102              0.358353   \n",
       "2           1                 0.270941              0.263430   \n",
       "3           1                 0.064546              0.064266   \n",
       "4           1                 0.133240              0.133156   \n",
       "5           1                 0.020862              0.020312   \n",
       "\n",
       "   metrics.exact.f1  metrics.fuzzy.precision  metrics.fuzzy.recall  \\\n",
       "0          0.013894                 0.298027              0.273680   \n",
       "1          0.361248                 0.793954              0.783383   \n",
       "2          0.266274                 0.686891              0.661890   \n",
       "3          0.064222                 0.530839              0.524796   \n",
       "4          0.132834                 0.588515              0.593496   \n",
       "5          0.020562                 0.455415              0.439280   \n",
       "\n",
       "   metrics.fuzzy.f1  \n",
       "0          0.282035  \n",
       "1          0.786429  \n",
       "2          0.671487  \n",
       "3          0.526424  \n",
       "4          0.588394  \n",
       "5          0.445118  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.json_normalize(experiments).drop(columns=[\"commit\"])\n",
    "print(f\"{len(df)} experiments before preprocessing\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 experiments after preprocessing\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>params.task</th>\n",
       "      <th>params.train.dataset.path</th>\n",
       "      <th>params.train.dataset.name</th>\n",
       "      <th>params.train.dataset.split</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.train.ensemble</th>\n",
       "      <th>params.evaluation.dataset.path</th>\n",
       "      <th>params.evaluation.dataset.name</th>\n",
       "      <th>params.evaluation.dataset.split</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>workspace</td>\n",
       "      <td>None</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ed74cb3591c364bf44234fe0c76b1a493846c358</td>\n",
       "      <td>alone-mesh</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7</td>\n",
       "      <td>slack-poss</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f939aab33f08dd257d0e54960c02affa57ff8733</td>\n",
       "      <td>group-nuke</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d82bf43700c686be11581eceae44b54b04b1299c</td>\n",
       "      <td>zippy-cane</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6600c85835c4d5dd5ff822f952838e0eaf0351c2</td>\n",
       "      <td>sated-pond</td>\n",
       "      <td>erx</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>train[:100]</td>\n",
       "      <td>noop</td>\n",
       "      <td>no</td>\n",
       "      <td>bdsaglam/web_nlg-erx-concat</td>\n",
       "      <td>release_v3.0_en</td>\n",
       "      <td>dev[:100]</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id        name params.task  \\\n",
       "0                                 workspace        None         erx   \n",
       "1  ed74cb3591c364bf44234fe0c76b1a493846c358  alone-mesh         erx   \n",
       "2  fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7  slack-poss         erx   \n",
       "3  f939aab33f08dd257d0e54960c02affa57ff8733  group-nuke         erx   \n",
       "4  d82bf43700c686be11581eceae44b54b04b1299c  zippy-cane         erx   \n",
       "5  6600c85835c4d5dd5ff822f952838e0eaf0351c2  sated-pond         erx   \n",
       "\n",
       "     params.train.dataset.path params.train.dataset.name  \\\n",
       "0  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "1  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "2  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "3  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "4  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "5  bdsaglam/web_nlg-erx-concat           release_v3.0_en   \n",
       "\n",
       "  params.train.dataset.split params.train.optimizer params.train.ensemble  \\\n",
       "0                train[:100]                   noop                    no   \n",
       "1                train[:100]           bfsrs-medium                    no   \n",
       "2                train[:100]           bfsrs-medium                    no   \n",
       "3                train[:100]          miprov2-light                    no   \n",
       "4                train[:100]          miprov2-light                    no   \n",
       "5                train[:100]                   noop                    no   \n",
       "\n",
       "  params.evaluation.dataset.path params.evaluation.dataset.name  \\\n",
       "0    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "1    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "2    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "3    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "4    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "5    bdsaglam/web_nlg-erx-concat                release_v3.0_en   \n",
       "\n",
       "  params.evaluation.dataset.split params.lm.model  params.lm.temperature  \\\n",
       "0                       dev[:100]      llama-3-8b                    0.0   \n",
       "1                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "2                       dev[:100]      llama-3-8b                    0.0   \n",
       "3                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "4                       dev[:100]      llama-3-8b                    0.0   \n",
       "5                       dev[:100]    qwen-2.5-32b                    0.0   \n",
       "\n",
       "   params.run  metrics.exact.precision  metrics.exact.recall  \\\n",
       "0           1                 0.014586              0.013411   \n",
       "1           1                 0.366102              0.358353   \n",
       "2           1                 0.270941              0.263430   \n",
       "3           1                 0.064546              0.064266   \n",
       "4           1                 0.133240              0.133156   \n",
       "5           1                 0.020862              0.020312   \n",
       "\n",
       "   metrics.exact.f1  metrics.fuzzy.precision  metrics.fuzzy.recall  \\\n",
       "0          0.013894                 0.298027              0.273680   \n",
       "1          0.361248                 0.793954              0.783383   \n",
       "2          0.266274                 0.686891              0.661890   \n",
       "3          0.064222                 0.530839              0.524796   \n",
       "4          0.132834                 0.588515              0.593496   \n",
       "5          0.020562                 0.455415              0.439280   \n",
       "\n",
       "   metrics.fuzzy.f1  \n",
       "0          0.282035  \n",
       "1          0.786429  \n",
       "2          0.671487  \n",
       "3          0.526424  \n",
       "4          0.588394  \n",
       "5          0.445118  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]\n",
    "df.dropna(subset=param_cols + metric_cols, inplace=True, how=\"any\")\n",
    "df.drop_duplicates(subset=param_cols, inplace=True)\n",
    "\n",
    "print(f\"{len(df)} experiments after preprocessing\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_tuple(x):\n",
    "    return tuple(sorted(x))\n",
    "\n",
    "run_counts = (\n",
    "    df.groupby(param_cols[:-1])[\n",
    "        \"params.run\"\n",
    "    ]\n",
    "    .aggregate(sorted_tuple)\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- params.task\n",
      "\terx\n",
      "- params.train.dataset.path\n",
      "\tbdsaglam/web_nlg-erx-concat\n",
      "- params.train.dataset.name\n",
      "\trelease_v3.0_en\n",
      "- params.train.dataset.split\n",
      "\ttrain[:100]\n",
      "- params.train.optimizer\n",
      "\tbfsrs-medium\n",
      "\tmiprov2-light\n",
      "\tnoop\n",
      "- params.train.ensemble\n",
      "\tno\n",
      "- params.evaluation.dataset.path\n",
      "\tbdsaglam/web_nlg-erx-concat\n",
      "- params.evaluation.dataset.name\n",
      "\trelease_v3.0_en\n",
      "- params.evaluation.dataset.split\n",
      "\tdev[:100]\n",
      "- params.lm.model\n",
      "\tllama-3-8b\n",
      "\tqwen-2.5-32b\n",
      "- params.lm.temperature\n",
      "\t0.0\n",
      "- params.run\n",
      "\t(1,)\n"
     ]
    }
   ],
   "source": [
    "for col in run_counts.columns:\n",
    "    print(f\"- {col}\")\n",
    "    for value in run_counts[col].unique():\n",
    "        print(f\"\\t{value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('exps.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = [col for col in df.columns if col.startswith(\"params.\")]\n",
    "metric_cols = [col for col in df.columns if col.startswith(\"metrics.\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.lm.temperature</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366102</td>\n",
       "      <td>0.358353</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.793954</td>\n",
       "      <td>0.783383</td>\n",
       "      <td>0.786429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.270941</td>\n",
       "      <td>0.263430</td>\n",
       "      <td>0.266274</td>\n",
       "      <td>0.686891</td>\n",
       "      <td>0.661890</td>\n",
       "      <td>0.671487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133240</td>\n",
       "      <td>0.133156</td>\n",
       "      <td>0.132834</td>\n",
       "      <td>0.588515</td>\n",
       "      <td>0.593496</td>\n",
       "      <td>0.588394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064546</td>\n",
       "      <td>0.064266</td>\n",
       "      <td>0.064222</td>\n",
       "      <td>0.530839</td>\n",
       "      <td>0.524796</td>\n",
       "      <td>0.526424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>noop</td>\n",
       "      <td>qwen-2.5-32b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020862</td>\n",
       "      <td>0.020312</td>\n",
       "      <td>0.020562</td>\n",
       "      <td>0.455415</td>\n",
       "      <td>0.439280</td>\n",
       "      <td>0.445118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.013411</td>\n",
       "      <td>0.013894</td>\n",
       "      <td>0.298027</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.282035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  params.train.optimizer params.lm.model  params.lm.temperature  \\\n",
       "1           bfsrs-medium    qwen-2.5-32b                    0.0   \n",
       "2           bfsrs-medium      llama-3-8b                    0.0   \n",
       "4          miprov2-light      llama-3-8b                    0.0   \n",
       "3          miprov2-light    qwen-2.5-32b                    0.0   \n",
       "5                   noop    qwen-2.5-32b                    0.0   \n",
       "0                   noop      llama-3-8b                    0.0   \n",
       "\n",
       "   metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "1                 0.366102              0.358353          0.361248   \n",
       "2                 0.270941              0.263430          0.266274   \n",
       "4                 0.133240              0.133156          0.132834   \n",
       "3                 0.064546              0.064266          0.064222   \n",
       "5                 0.020862              0.020312          0.020562   \n",
       "0                 0.014586              0.013411          0.013894   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "1                 0.793954              0.783383          0.786429  \n",
       "2                 0.686891              0.661890          0.671487  \n",
       "4                 0.588515              0.593496          0.588394  \n",
       "3                 0.530839              0.524796          0.526424  \n",
       "5                 0.455415              0.439280          0.445118  \n",
       "0                 0.298027              0.273680          0.282035  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['params.train.optimizer', 'params.lm.model', 'params.lm.temperature', *metric_cols]].sort_values(by='metrics.fuzzy.f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
