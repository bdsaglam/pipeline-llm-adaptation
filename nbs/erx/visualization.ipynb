{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>params.train.optimizer</th>\n",
       "      <th>params.program.prompting</th>\n",
       "      <th>params.lm.model</th>\n",
       "      <th>params.run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>noop</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>low</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irony-gust</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outer-ring</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moral-prof</td>\n",
       "      <td>noop</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>high</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spicy-teff</td>\n",
       "      <td>noop</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b-sft</td>\n",
       "      <td>medium</td>\n",
       "      <td>0.826799</td>\n",
       "      <td>0.806647</td>\n",
       "      <td>0.814956</td>\n",
       "      <td>0.942006</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.929080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>epoxy-dele</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164665</td>\n",
       "      <td>0.159790</td>\n",
       "      <td>0.161087</td>\n",
       "      <td>0.549267</td>\n",
       "      <td>0.538236</td>\n",
       "      <td>0.540178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>girly-cuss</td>\n",
       "      <td>noop</td>\n",
       "      <td>structured</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017500</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>0.335013</td>\n",
       "      <td>0.341740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name params.train.optimizer params.program.prompting params.lm.model  \\\n",
       "1  lathy-jaws                   noop                      sft  llama-3-8b-sft   \n",
       "2  bluff-dita             bfsrs-high               structured      llama-3-8b   \n",
       "3  irony-gust         miprov2-medium               structured      llama-3-8b   \n",
       "4  outer-ring           bfsrs-medium               structured      llama-3-8b   \n",
       "5  moral-prof                   noop                      sft  llama-3-8b-sft   \n",
       "6  spicy-teff                   noop                      sft  llama-3-8b-sft   \n",
       "7  epoxy-dele          miprov2-light               structured      llama-3-8b   \n",
       "8  girly-cuss                   noop               structured      llama-3-8b   \n",
       "\n",
       "  params.run  metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "1        low                 0.630100              0.622543          0.623483   \n",
       "2          1                 0.280462              0.275396          0.276618   \n",
       "3          1                 0.250988              0.233233          0.240662   \n",
       "4          1                 0.255153              0.246698          0.249767   \n",
       "5       high                 0.945660              0.939192          0.941871   \n",
       "6     medium                 0.826799              0.806647          0.814956   \n",
       "7          1                 0.164665              0.159790          0.161087   \n",
       "8          1                 0.018212              0.017030          0.017500   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \n",
       "1                 0.850379              0.847531          0.844171  \n",
       "2                 0.676080              0.664274          0.666510  \n",
       "3                 0.653248              0.607018          0.625459  \n",
       "4                 0.651775              0.629756          0.637432  \n",
       "5                 0.980038              0.973275          0.976060  \n",
       "6                 0.942006              0.920719          0.929080  \n",
       "7                 0.549267              0.538236          0.540178  \n",
       "8                 0.356735              0.335013          0.341740  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json('exps.jsonl', lines=True)\n",
    "\n",
    "df.dropna(inplace=True, how='any')\n",
    "\n",
    "mask = df['params.evaluation.dataset.split'] == 'dev'\n",
    "df = df[mask].copy()\n",
    "\n",
    "cols2drop = ['id']\n",
    "for col in df.columns:\n",
    "    if len(df[col].unique()) == 1:\n",
    "        cols2drop.append(col)\n",
    "df.drop(columns=cols2drop, inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    'structured': 'prompting',\n",
    "    'sft': 'sft',\n",
    "}\n",
    "df['params.program.prompting'] = df['params.program.prompting'].map(mapping.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['params.lm.model'] = df['params.lm.model'].map(lambda x: x.replace('-sft', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    1: 100,\n",
    "    'low': 100,\n",
    "    'medium': 1000,\n",
    "    'high': 8870,\n",
    "}\n",
    "\n",
    "def get_adaptation_n_sample(row):\n",
    "    if row['params.program.prompting'] == 'sft':\n",
    "        return mapping[row['params.run']]\n",
    "    \n",
    "    if row['params.program.prompting'] == 'prompting':\n",
    "        optimizer = row['params.train.optimizer']\n",
    "        if optimizer == 'noop':\n",
    "            return 0\n",
    "        if optimizer == 'miprov2-light':\n",
    "            return 4\n",
    "        if optimizer == 'miprov2-medium':\n",
    "            return 8\n",
    "        if optimizer == 'bfsrs-light':\n",
    "            return 4\n",
    "        if optimizer == 'bfsrs-medium':\n",
    "            return 8\n",
    "        if optimizer == 'bfsrs-high':\n",
    "            return 16\n",
    "        if optimizer == 'bfsrs-ulti':\n",
    "            return 32\n",
    "    \n",
    "    \n",
    "    raise ValueError(f'Unknown method: {row[\"params.program.prompting\"]}')\n",
    "\n",
    "df['params.adaptation.n_sample'] = df.apply(get_adaptation_n_sample, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_cols = [col for col in df.columns if 'params' in col]\n",
    "metric_cols = [col for col in df.columns if 'metrics' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train.optimizer</th>\n",
       "      <th>program.prompting</th>\n",
       "      <th>lm.model</th>\n",
       "      <th>run</th>\n",
       "      <th>metrics.exact.precision</th>\n",
       "      <th>metrics.exact.recall</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.precision</th>\n",
       "      <th>metrics.fuzzy.recall</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "      <th>adaptation.n_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lathy-jaws</td>\n",
       "      <td>noop</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>low</td>\n",
       "      <td>0.630100</td>\n",
       "      <td>0.622543</td>\n",
       "      <td>0.623483</td>\n",
       "      <td>0.850379</td>\n",
       "      <td>0.847531</td>\n",
       "      <td>0.844171</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bluff-dita</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.280462</td>\n",
       "      <td>0.275396</td>\n",
       "      <td>0.276618</td>\n",
       "      <td>0.676080</td>\n",
       "      <td>0.664274</td>\n",
       "      <td>0.666510</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>irony-gust</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250988</td>\n",
       "      <td>0.233233</td>\n",
       "      <td>0.240662</td>\n",
       "      <td>0.653248</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.625459</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>outer-ring</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>prompting</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255153</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.249767</td>\n",
       "      <td>0.651775</td>\n",
       "      <td>0.629756</td>\n",
       "      <td>0.637432</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>moral-prof</td>\n",
       "      <td>noop</td>\n",
       "      <td>sft</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>high</td>\n",
       "      <td>0.945660</td>\n",
       "      <td>0.939192</td>\n",
       "      <td>0.941871</td>\n",
       "      <td>0.980038</td>\n",
       "      <td>0.973275</td>\n",
       "      <td>0.976060</td>\n",
       "      <td>8870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name train.optimizer program.prompting    lm.model   run  \\\n",
       "1  lathy-jaws            noop               sft  llama-3-8b   low   \n",
       "2  bluff-dita      bfsrs-high         prompting  llama-3-8b     1   \n",
       "3  irony-gust  miprov2-medium         prompting  llama-3-8b     1   \n",
       "4  outer-ring    bfsrs-medium         prompting  llama-3-8b     1   \n",
       "5  moral-prof            noop               sft  llama-3-8b  high   \n",
       "\n",
       "   metrics.exact.precision  metrics.exact.recall  metrics.exact.f1  \\\n",
       "1                 0.630100              0.622543          0.623483   \n",
       "2                 0.280462              0.275396          0.276618   \n",
       "3                 0.250988              0.233233          0.240662   \n",
       "4                 0.255153              0.246698          0.249767   \n",
       "5                 0.945660              0.939192          0.941871   \n",
       "\n",
       "   metrics.fuzzy.precision  metrics.fuzzy.recall  metrics.fuzzy.f1  \\\n",
       "1                 0.850379              0.847531          0.844171   \n",
       "2                 0.676080              0.664274          0.666510   \n",
       "3                 0.653248              0.607018          0.625459   \n",
       "4                 0.651775              0.629756          0.637432   \n",
       "5                 0.980038              0.973275          0.976060   \n",
       "\n",
       "   adaptation.n_sample  \n",
       "1                  100  \n",
       "2                   16  \n",
       "3                    8  \n",
       "4                    8  \n",
       "5                 8870  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_rename_mapping = {col: col.replace(\"params.\", \"\") for col in df.columns}\n",
    "df.rename(columns=column_rename_mapping, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_mapping = {\n",
    "    \"train.optimizer\": \"prompt.optimizer\",\n",
    "    \"program.prompting\": \"adaptation.method\",\n",
    "}\n",
    "df.rename(columns=column_rename_mapping, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_order = [\n",
    "    'adaptation.method',\n",
    "    'adaptation.n_sample',\n",
    "    'prompt.optimizer',\n",
    "    'lm.model',\n",
    "    'metrics.exact.f1',\n",
    "    'metrics.fuzzy.f1',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set precision to 2 for metric cols\n",
    "df[metric_cols] = df[metric_cols].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adaptation.method</th>\n",
       "      <th>adaptation.n_sample</th>\n",
       "      <th>prompt.optimizer</th>\n",
       "      <th>lm.model</th>\n",
       "      <th>metrics.exact.f1</th>\n",
       "      <th>metrics.fuzzy.f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sft</td>\n",
       "      <td>8870</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sft</td>\n",
       "      <td>1000</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sft</td>\n",
       "      <td>100</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prompting</td>\n",
       "      <td>16</td>\n",
       "      <td>bfsrs-high</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>prompting</td>\n",
       "      <td>8</td>\n",
       "      <td>bfsrs-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prompting</td>\n",
       "      <td>8</td>\n",
       "      <td>miprov2-medium</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>prompting</td>\n",
       "      <td>4</td>\n",
       "      <td>miprov2-light</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>prompting</td>\n",
       "      <td>0</td>\n",
       "      <td>noop</td>\n",
       "      <td>llama-3-8b</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  adaptation.method  adaptation.n_sample prompt.optimizer    lm.model  \\\n",
       "5               sft                 8870             noop  llama-3-8b   \n",
       "6               sft                 1000             noop  llama-3-8b   \n",
       "1               sft                  100             noop  llama-3-8b   \n",
       "2         prompting                   16       bfsrs-high  llama-3-8b   \n",
       "4         prompting                    8     bfsrs-medium  llama-3-8b   \n",
       "3         prompting                    8   miprov2-medium  llama-3-8b   \n",
       "7         prompting                    4    miprov2-light  llama-3-8b   \n",
       "8         prompting                    0             noop  llama-3-8b   \n",
       "\n",
       "   metrics.exact.f1  metrics.fuzzy.f1  \n",
       "5              0.94              0.98  \n",
       "6              0.81              0.93  \n",
       "1              0.62              0.84  \n",
       "2              0.28              0.67  \n",
       "4              0.25              0.64  \n",
       "3              0.24              0.63  \n",
       "7              0.16              0.54  \n",
       "8              0.02              0.34  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in df['lm.model'].unique():\n",
    "    _df = df[df['lm.model'] == model]\n",
    "    display(_df[col_order].sort_values(by='metrics.fuzzy.f1', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
