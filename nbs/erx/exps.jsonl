{"id":"workspace","name":null,"params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:1000]","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0145859688,"metrics.exact.recall":0.0134111069,"metrics.exact.f1":0.0138939681,"metrics.fuzzy.precision":0.2980273675,"metrics.fuzzy.recall":0.2736804603,"metrics.fuzzy.f1":0.2820348332}
{"id":"8a95fd4dc54ea708f0f7421b291c9ec0e1c8f550","name":"lathy-jaws","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"sft","params.lm.model":"llama-3-8b-sft","params.lm.temperature":0.0,"params.run":"low","metrics.exact.precision":0.6301002433,"metrics.exact.recall":0.6225433159,"metrics.exact.f1":0.6234832861,"metrics.fuzzy.precision":0.8503794425,"metrics.fuzzy.recall":0.8475311959,"metrics.fuzzy.f1":0.8441705984}
{"id":"10018c1a534cbb1bb093856fe741782b063885d5","name":"bluff-dita","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"bfsrs-high","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.2804624603,"metrics.exact.recall":0.275395903,"metrics.exact.f1":0.2766184175,"metrics.fuzzy.precision":0.6760802799,"metrics.fuzzy.recall":0.6642742062,"metrics.fuzzy.f1":0.6665101477}
{"id":"d3bb54eb8efdc0a2bb5c86befb6b9c5cd0159ebf","name":"irony-gust","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"miprov2-medium","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.2509879374,"metrics.exact.recall":0.2332327157,"metrics.exact.f1":0.2406621615,"metrics.fuzzy.precision":0.6532476725,"metrics.fuzzy.recall":0.6070183302,"metrics.fuzzy.f1":0.6254594188}
{"id":"38621dd5eb7f657d0ed4c3060ec1bfdaab830cda","name":"outer-ring","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"bfsrs-medium","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.2551525662,"metrics.exact.recall":0.2466977376,"metrics.exact.f1":0.2497669531,"metrics.fuzzy.precision":0.6517752509,"metrics.fuzzy.recall":0.6297562349,"metrics.fuzzy.f1":0.6374320446}
{"id":"207289e5a394e3f9ae82cf08aea3d2ca07e190ba","name":"moral-prof","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"sft","params.lm.model":"llama-3-8b-sft","params.lm.temperature":0.0,"params.run":"high","metrics.exact.precision":0.9456603325,"metrics.exact.recall":0.9391915645,"metrics.exact.f1":0.9418709388,"metrics.fuzzy.precision":0.9800378486,"metrics.fuzzy.recall":0.9732752624,"metrics.fuzzy.f1":0.9760604083}
{"id":"e20f45a313f10b09f83c05fdb44f275d52da7799","name":"spicy-teff","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"sft","params.lm.model":"llama-3-8b-sft","params.lm.temperature":0.0,"params.run":"medium","metrics.exact.precision":0.8267994989,"metrics.exact.recall":0.8066470542,"metrics.exact.f1":0.8149561875,"metrics.fuzzy.precision":0.9420056737,"metrics.fuzzy.recall":0.9207190905,"metrics.fuzzy.f1":0.9290798517}
{"id":"8af6e338f987cfa912d7ee566a61bd24f956fd7c","name":"epoxy-dele","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"miprov2-light","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.1646646401,"metrics.exact.recall":0.1597900702,"metrics.exact.f1":0.1610867911,"metrics.fuzzy.precision":0.5492672693,"metrics.fuzzy.recall":0.5382359666,"metrics.fuzzy.f1":0.5401783354}
{"id":"c4c203b34fff9acc3052b01148457799d70463a8","name":"girly-cuss","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0182116191,"metrics.exact.recall":0.0170302127,"metrics.exact.f1":0.0175003737,"metrics.fuzzy.precision":0.3567345619,"metrics.fuzzy.recall":0.335013168,"metrics.fuzzy.f1":0.3417404815}
{"id":"6f84f2616434f0cb73f78dd99349821288535df6","name":"metal-pons","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"bfsrs-medium","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:1000]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.3778390653,"metrics.exact.recall":0.3670841762,"metrics.exact.f1":0.3706447319,"metrics.fuzzy.precision":0.797541413,"metrics.fuzzy.recall":0.7791908722,"metrics.fuzzy.f1":0.7837461156}
{"id":"8db0681d601021cfecaa922e7a118c7afa21a0fa","name":"crumb-geum","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:1000]","params.program.prompting":"sft","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.4512513033,"metrics.exact.recall":0.4346754184,"metrics.exact.f1":0.4379758117,"metrics.fuzzy.precision":0.7621504947,"metrics.fuzzy.recall":0.7409624638,"metrics.fuzzy.f1":0.7429357854}
{"id":"914f4e695eca42802fb2d2b3ab2233cf979773a6","name":"myoid-kefs","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"miprov2-light","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:1000]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0720776276,"metrics.exact.recall":0.0699216617,"metrics.exact.f1":0.0706836772,"metrics.fuzzy.precision":0.5326388056,"metrics.fuzzy.recall":0.5235897155,"metrics.fuzzy.f1":0.5256732187}
{"id":"6d745e03f12c22dca0275b04496e83e8feb903a7","name":"butch-keek","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:1000]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0169734337,"metrics.exact.recall":0.0167210978,"metrics.exact.f1":0.016768704,"metrics.fuzzy.precision":0.4476802209,"metrics.fuzzy.recall":0.4305049628,"metrics.fuzzy.f1":0.4360404498}
{"id":"workspace","name":null,"params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0145859688,"metrics.exact.recall":0.0134111069,"metrics.exact.f1":0.0138939681,"metrics.fuzzy.precision":0.2980273675,"metrics.fuzzy.recall":0.2736804603,"metrics.fuzzy.f1":0.2820348332}
{"id":"ed74cb3591c364bf44234fe0c76b1a493846c358","name":"alone-mesh","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"bfsrs-medium","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.3661023876,"metrics.exact.recall":0.3583529592,"metrics.exact.f1":0.3612482661,"metrics.fuzzy.precision":0.7939542483,"metrics.fuzzy.recall":0.783382611,"metrics.fuzzy.f1":0.7864293722}
{"id":"fa88c58fe75e8ecb78ffa4fdd79a9b1538ad40a7","name":"slack-poss","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"bfsrs-medium","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.2709409188,"metrics.exact.recall":0.2634303612,"metrics.exact.f1":0.2662735109,"metrics.fuzzy.precision":0.6868910395,"metrics.fuzzy.recall":0.6618903894,"metrics.fuzzy.f1":0.6714865529}
{"id":"f939aab33f08dd257d0e54960c02affa57ff8733","name":"group-nuke","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"miprov2-light","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.0645462782,"metrics.exact.recall":0.0642659004,"metrics.exact.f1":0.0642215557,"metrics.fuzzy.precision":0.5308394167,"metrics.fuzzy.recall":0.5247961812,"metrics.fuzzy.f1":0.5264240891}
{"id":"d82bf43700c686be11581eceae44b54b04b1299c","name":"zippy-cane","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"miprov2-light","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"llama-3-8b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.1332400648,"metrics.exact.recall":0.1331560302,"metrics.exact.f1":0.1328341625,"metrics.fuzzy.precision":0.5885152193,"metrics.fuzzy.recall":0.5934959778,"metrics.fuzzy.f1":0.5883939957}
{"id":"6600c85835c4d5dd5ff822f952838e0eaf0351c2","name":"sated-pond","params.task":"erx","params.train.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.train.dataset.name":"release_v3.0_en","params.train.dataset.split":"train[:100]","params.train.optimizer":"noop","params.train.ensemble":"no","params.evaluation.dataset.path":"bdsaglam\/web_nlg-erx-concat","params.evaluation.dataset.name":"release_v3.0_en","params.evaluation.dataset.split":"dev[:100]","params.program.prompting":"structured","params.lm.model":"qwen-2.5-32b","params.lm.temperature":0.0,"params.run":1,"metrics.exact.precision":0.020862133,"metrics.exact.recall":0.0203116883,"metrics.exact.f1":0.0205623246,"metrics.fuzzy.precision":0.4554146627,"metrics.fuzzy.recall":0.4392800965,"metrics.fuzzy.f1":0.4451181865}
